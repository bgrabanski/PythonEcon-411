{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd382427",
   "metadata": {},
   "source": [
    "# Project 9 - Working with OLS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c445ea8",
   "metadata": {},
   "source": [
    "Having built statistics functions, we are now ready to build a function for regression analysis. We will start by building the an regression. We will use linear algebra to estimate parameters that minimize the sum of the squared errors. This is an ordinary least squares regression. \n",
    "\n",
    "An OLS regression with one exogenous variable takes the form. \n",
    "\n",
    "$y = \\alpha + \\beta_1x_1 + \\mu $\n",
    "\n",
    "$\\beta_0 = \\alpha + \\mu$\n",
    "\n",
    "We merge the error term, which represents bias in the data, with alpha to yield the constant, $\\beta_0$. This is necessary since OLS assumes an unbiased estimator where:\n",
    "\n",
    "$\\sum_{i=0}^{n-1} e_{i}=0$\n",
    "\n",
    "Each estimate of a point created from a particular observation takes the form.\n",
    "\n",
    "$y_i = \\beta_0 + \\beta_1x_{1,i} + e_i$\n",
    "\n",
    "This can be generalized to include k exogenous variables:\n",
    "\n",
    "$y_i = \\beta_0 + (\\sum_{j=1}^{k} \\beta_jx_{i,j}) + e_i$\n",
    "\n",
    "Ideally, we want to form a prediction where, on average, the right-hand side of the equation  yields the correct value on the left-hand side. When we perform an OLS regression, we form a predictor that minimizes the sum of the distance between each predicted value and the observed value drawn from the data. For example, if the prediction for a particular value of y is 8, and the actual value is 10, the error of the prediction is -2 and the squared error is 4.\n",
    "\n",
    "To find the function that minimizes the sum squared errors, we will use matrix algebra, also known as linear algebra. For those unfamiliar, the next section uses the numpy library to perform matrix operations. For clarity, we will review the linear algebra functions that we will use with simple examples.\n",
    "\n",
    "## Linear Algebra for OLS\n",
    "\n",
    "We solve the following function for a vector of beta values ($\\beta$), constants whose values represent estimates of the effect of variables in the set **_X_** on the selected endogenously generate variable $y$. The matrix **_X_** also includes a vector of ones used to estimate the constant $\\beta_0$.\n",
    "\n",
    "$\\beta = (X'X)^{-1}X'Y$\n",
    "\n",
    "$Y =$ Observations for Endogenous Variable\n",
    "\n",
    "$X =$ Observations for Exogenous Variables\n",
    "\n",
    "$X' =$ $X$-transpose\n",
    "\n",
    "$(X'X)^{-1} =$ Inverse of $X'X$\n",
    "\n",
    "### Inverting a Matrix\n",
    "\n",
    "In reviewing the linear equation for estimating $\\beta$, we confront two unique operations worth understanding. Included in these are some key concepts in linear algebra, including the identity matrix $I$ and linear independence. The best way to understand these concepts is by working with some sample vectors. Consider the matrix $X$ consisting of vectors $x_0$,$x_1$,â€¦,$x_{n-1}$,$x_n$. We must check that these vectors are linearly independent. We do this by joining $X$ with an identity matrix and thus create:\n",
    "\n",
    "$A = [XI]$\n",
    "\n",
    "We transform this to show that the product of $A$ and $X^{-1}$ is equal to the product of and an identity matrix, $I$ and $X^{-1}$\n",
    "\n",
    "$AX^{-1} = [XI]X^{-1}$\n",
    "\n",
    "$AX^{-1} = [IX^{-1}]$\n",
    "\n",
    "Let us solve for $AX^{-1}$ using the following vectors for $X$. \n",
    "\n",
    "$\\begin{equation*}\n",
    "X = \\begin{bmatrix}\n",
    "1 & 2 & 1 \\\\\n",
    "4 & 1 & 5 \\\\\n",
    "6 & 8 & 6\n",
    "\\end{bmatrix}\n",
    "\\end{equation*}$\n",
    "\n",
    "Concatenate a 3 X 3 identity matrix on the left of $X$:\n",
    "\n",
    "$\\begin{equation*}\n",
    "I = \\begin{bmatrix}\n",
    "1 & 0 & 0 \\\\\n",
    "0 & 1 & 0 \\\\\n",
    "0 & 0 & 1\n",
    "\\end{bmatrix}\n",
    "\\end{equation*}$\n",
    "\n",
    "$\\begin{equation*}\n",
    "[XI] = \\begin{bmatrix}\n",
    "1 & 2 & 1 & 1 & 0 & 0 \\\\\n",
    "4 & 1 & 5 & 0 & 1 & 0 \\\\\n",
    "6 & 8 & 6 & 0 & 0 & 1\n",
    "\\end{bmatrix}\n",
    "\\end{equation*}$\n",
    "\n",
    "If we perform row operations on $A$ to transform $X$ in $[XI]$ into $I$, then we $I$ will be transformed into $X^{-1}$:\n",
    "\n",
    "$\\begin{equation*}\n",
    "[XI] = \\begin{bmatrix}\n",
    "1 & 2 & 1 & 1 & 0 & 0 \\\\\n",
    "4 & 1 & 5 & 0 & 1 & 0 \\\\\n",
    "6 & 8 & 6 & 0 & 0 & 1\n",
    "\\end{bmatrix}\n",
    "\\end{equation*}$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "$\\begin{equation*}\n",
    "r_2 - 4r_1:\\begin{bmatrix}\n",
    "1 & 2 & 1 & 1 & 0 & 0 \\\\\n",
    "0 & -7 & 1 & -4 & 1 & 0 \\\\\n",
    "6 & 8 & 6 & 0 & 0 & 1\n",
    "\\end{bmatrix}\n",
    "\\end{equation*}$\n",
    "\n",
    "\n",
    "$\\begin{equation*}\n",
    "r_3 - 6r_1:\\begin{bmatrix}\n",
    "1 & 2 & 1 & 1 & 0 & 0 \\\\\n",
    "0 & -7 & 1 & -4 & 1 & 0 \\\\\n",
    "0 & -4 & 0 & -6 & 0 & 1\n",
    "\\end{bmatrix}\n",
    "\\end{equation*}$\n",
    "\n",
    "\n",
    "$\\begin{equation*}\n",
    "r_2 \\leftrightarrow r_3:\\begin{bmatrix}\n",
    "1 & 2 & 1 & 1 & 0 & 0 \\\\\n",
    "0 & -4 & 0 & -6 & 0 & 1\\\\\n",
    "0 & -7 & 1 & -4 & 1 & 0 \n",
    "\\end{bmatrix}\n",
    "\\end{equation*}$\n",
    "\n",
    "$\\begin{equation*}\n",
    "r_2/{-4}:\\begin{bmatrix}\n",
    "1 & 2 & 1 & 1 & 0 & 0 \\\\\n",
    "0 & 1 & 0 & 3/2 & 0 & -1/4\\\\\n",
    "0 & -7 & 1 & -4 & 1 & 0 \n",
    "\\end{bmatrix}\n",
    "\\end{equation*}$\n",
    "\n",
    "$\\begin{equation*}\n",
    "r_3 + 7r_2:\\begin{bmatrix}\n",
    "1 & 2 & 1 & 1 & 0 & 0 \\\\\n",
    "0 & 1 & 0 & 3/2 & 0 & -1/4\\\\\n",
    "0 & 0 & 1 & 13/2 & 1 & -7/4 \n",
    "\\end{bmatrix}\n",
    "\\end{equation*}$\n",
    "\n",
    "$\\begin{equation*}\n",
    "r_1 + -2r_2 - r_3:\\begin{bmatrix}\n",
    "1 & 0 & 0 & -17/2 & -1 & 9/4 \\\\\n",
    "0 & 1 & 0 & 3/2 & 0 & -1/4\\\\\n",
    "0 & 0 & 1 & 13/2 & 1 & -7/4 \n",
    "\\end{bmatrix}\n",
    "\\end{equation*}$\n",
    "\n",
    "$\\begin{equation*}\n",
    "IX^{-1}=\\begin{bmatrix}\n",
    "1 & 0 & 0 & -8.5 & -1 & 2.25 \\\\\n",
    "0 & 1 & 0 & 1.5 & 0 & -0.25\\\\\n",
    "0 & 0 & 1 & 6.5 & 1 & -1.75 \n",
    "\\end{bmatrix}\n",
    "\\end{equation*}$\n",
    "\n",
    "$\\begin{equation*}\n",
    "X^{-1}=\\begin{bmatrix}\n",
    "-8.5 & -1 & 2.25 \\\\\n",
    "1.5 & 0 & -0.25\\\\\n",
    "6.5 & 1 & -1.75 \n",
    "\\end{bmatrix}\n",
    "\\end{equation*}$\n",
    "\n",
    "By transforming $X$ in matrix $XI$ into an identity matrix, we transform the $I$ matrix into $X^{-1}$. This also confirms that the vectors comprising X are independent, meaning that one vector in the set comprising $X$ cannot be formed from the combination and or transformation of the others. A fundamental assumption of regression analysis is that data generated from factors believed to determine the y-values are independent of one another.\n",
    "\n",
    "### Linear Algebra in _numpy_\n",
    "\n",
    "We can check this using linear algebra functions in numpy. We start by creating numpy arrays that we will transform into vectors in the second step. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3b614f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 1]\n",
      "[4 1 5]\n",
      "[6 8 6]\n",
      "[1 2 1]\n",
      "[4 1 5]\n",
      "[6 8 6]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# create basis for matrix in np.array\n",
    "x1 = np.array([1,2,1])\n",
    "x2 = np.array([4,1,5])\n",
    "x3 = np.array([6,8,6])\n",
    "print(x1,x2,x3, sep = \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44df2fa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 1]]\n",
      "[[4 1 5]]\n",
      "[[6 8 6]]\n",
      "[[1 2 1]]\n",
      "[[4 1 5]]\n",
      "[[6 8 6]]\n"
     ]
    }
   ],
   "source": [
    "# convert np.arrays to np.matrix values. \n",
    "x1 = np.matrix(x1)\n",
    "x2 = np.matrix(x2)\n",
    "x3 = np.matrix(x3)\n",
    "print(x1,x2,x3, sep = \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa90a357",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the separate matrix values into one matrix\n",
    "X = np.concatenate((x1,x2,x3))\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600b06d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to create an inverse matrix, we can just use X.getI(). This allows us to bypass the algebra\n",
    "X_inverse = X.getI()\n",
    "X_inverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aafcd9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to round out this number that was supposed to be zero, we use np.round\n",
    "np.round(X_inverse, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2bbcfd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Swaps i and j rows. Allows for transposition of data if it is unorganized or in a \n",
    "# difficult position. This allows for better computation\n",
    "X_transpose = X.getT()\n",
    "X_transpose"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55296c24",
   "metadata": {},
   "source": [
    "## Regression Function\n",
    "\n",
    "Now that we have learned the necessary operations, we can understand the operations of the regression function. If you would like to build your own regression module, reconstruct the scripts form Chapter 7. In this lesson, we will use the statsmodels OLS method to reconstruct and compare statistics from an OLS regression. \n",
    "\n",
    "Recall that we estimate the vector of beta parameters for each variable with the equation:\n",
    "\n",
    "$\\beta = (X'X)^{-1}X'Y$\n",
    "\n",
    "Each estimated $\\beta$ value is multiplied by each observation of the relevant exogenous variable estimate the effect of the value on the endogenous, $Y$, value.\n",
    "\n",
    "We will run a regression In order to estimate the parameters, we will need to import data, define the dependent variable and independent variables, and transform these into matrix objects. \n",
    "\n",
    "Let's use the data from chapter 6 with the addition real GDP per capita. This combined set of data is saved in the repository as a file created in chapter 8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d17463",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We now can use this linear algebra to calculate the betas in our regression. \n",
    "\n",
    "# Now we will import data and run a regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0fe100",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# download madison economic data from the source document. This GDP data goes back far\n",
    "# to virtually the beginning of recorded economics\n",
    "mgdp = pd.read_excel(\n",
    "    \"https://www.rug.nl/ggdc/historicaldevelopment/maddison/data/mpd2020.xlsx\",\n",
    "                    index_col = [0,2],\n",
    "                    parse_dates = True,\n",
    "                    sheet_name = \"Full data\")\n",
    "mgdp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265d2af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the excel file that we downloaded previously on the economic freedom of the world\n",
    "# 2022 master data. We are planning to incorporate the above data into this EFOTW data\n",
    "\n",
    "# make sure to parse_dates so that pandas recognizes dates correctly\n",
    "\n",
    "\n",
    "filename = \"efotw-2022-master-index-data-for-researchers-iso.xlsx\"\n",
    "data = pd.read_excel(filename,\n",
    "                    index_col = [2,0],\n",
    "                     header = [0],\n",
    "                     sheet_name = \"EFW Panel Data 2022 Report\")\n",
    "\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29372f2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# transform names so that they are more easily understandable. We have done this before in \n",
    "# previous lessons\n",
    "\n",
    "rename = {\"Panel Data Summary Index\": \"Summary\",\n",
    "         \"Area 1\":\"Size of Government\",\n",
    "         \"Area 2\":\"Legal System and Property Rights\",\n",
    "         \"Area 3\":\"Sound Money\",\n",
    "         \"Area 4\":\"Freedom to Trade Internationally\",\n",
    "         \"Area 5\":\"Regulation\"}\n",
    "\n",
    "# this will drop all rows with only null values and rename columns based on the above \n",
    "\n",
    "data = data.dropna(how=\"all\", axis = 1).rename(columns = rename)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c043286b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# we now concatenate the mgdp data into the \n",
    "data[\"RGDP Per Capita\"] = mgdp[\"gdppc\"]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc92da35",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# delete standard deviation column\n",
    "del  data[\"Standard Deviation of the 5 EFW Areas\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da5232a6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eedc2157",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.reset_index(inplace = True)\n",
    "data[\"Year\"] = data[\"Year\"].astype(str).astype(\"datetime64[ns]\").sort_index()\n",
    "data = data.set_index([\"ISO_Code_3\", \"Year\"]).sort_index()\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b96186c",
   "metadata": {},
   "outputs": [],
   "source": [
    "years = np.array(sorted(list(set(data.index.get_level_values(\"Year\")))))\n",
    "years = pd.date_range(years[0], years[-2], freq = \"AS\")\n",
    "countries = sorted(list(set(data.index.get_level_values(\"ISO_Code_3\"))))\n",
    "index_names = list(data.index.names)\n",
    "multi_index = pd.MultiIndex.from_product([countries, years[:-1]], names = data.index.names)\n",
    "data = data.reindex(multi_index)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c76a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we now save this file in an excel file\n",
    "data.to_excel(\"EFWAndRGDP.xls\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bffba0c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect the keys of this file\n",
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c6e363",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select subset for analysis\n",
    "data = data[data.keys()[3:]]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341adced",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort data in the by the index columns (previously defined first as iso code second as year)\n",
    "\n",
    "# it is possible to transform to datetime, but we did not cover it in this lesson. \n",
    "# contact Dr. Caton for more assistance\n",
    "\n",
    "data.sort_index(inplace = True)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8457e261",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_vars = list(data.keys())\n",
    "reg_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2b49cd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# separate columns for analysis. We are using Real GDP per capita as our basis for Y in this analysis\n",
    "\n",
    "reg_data = data[reg_vars].dropna()\n",
    "y_var = [reg_vars[-1]]\n",
    "x_vars = reg_vars[2:-1]\n",
    "y_var, x_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a848bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# already imported statsmodel.api\n",
    "\n",
    "# set x and y variables as well as add constant\n",
    "y = reg_data[y_var]\n",
    "X = reg_data[x_vars]\n",
    "X[\"Constant\"] = 1\n",
    "results = sm.OLS(y, X).fit()\n",
    "\n",
    "# X.values is a matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b026953",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a summary by using results.summary() to view normal regression\n",
    "\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6196740",
   "metadata": {},
   "outputs": [],
   "source": [
    "#use predictor to develop a prediction\n",
    "\n",
    "predictor = results.predict()\n",
    "\n",
    "\n",
    "# add a column for predicted value based on regression\n",
    "reg_data[y_var[0] + \" Predictor\"] = predictor\n",
    "reg_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b3cffe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caluculate SSE, SSR, & SST\n",
    "# SSE = sum square errors, SSR = sum squared from regression, SST = total sum squares\n",
    "\n",
    "\n",
    "# convert these to name[0] for this next analysis. Make sure all data has same number of rows.\n",
    "\n",
    "y_hat = reg_data[y_var[0] + \" Predictor\"]\n",
    "y_mean = reg_data[y_var[0]].mean()\n",
    "y = reg_data[y_var[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec14b2d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# calculate residuals by subtracting prediction from actual\n",
    "reg_data[\"Residuals\"] = (y.sub(y_hat))\n",
    "reg_data[\"Squared Explained\"] = y_hat.sub(y_mean).pow(2)\n",
    "reg_data[\"Squared Residuals\"] = y.sub(y_hat).pow(2)\n",
    "reg_data[\"Squared Totals\"] = y.sub(y_mean).pow(2)\n",
    "\n",
    "reg_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb4caa5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Take sums of columns so we can caluclate the SSR, SSE, and SST\n",
    "\n",
    "SSR = reg_data[\"Squared Explained\"].sum()\n",
    "SSE = reg_data[\"Squared Residuals\"].sum()\n",
    "SST = reg_data[\"Squared Totals\"].sum()\n",
    "SSR, SSE, SST"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae649d83",
   "metadata": {},
   "source": [
    "# Calculate Estimator Variance \n",
    "With the sum of squared errors calculated, the next step is to calculate the estimator variance and use this to construct the covariance matrix. The covariance matrix is used to derive the standard errors and related statistics for each estimated coefficient.\n",
    "\n",
    "We estimate the variance of the error term of the estimator for the dependent variable. \n",
    "\n",
    "$\\sigma^2 = \\frac{SSE}{n-k}$\n",
    "\n",
    "$n = $number of observations\n",
    "\n",
    "$k = $number of independent variables\n",
    "\n",
    "An increase in the number of exogenous variables tends ot increase the fit of a model. By dividing the $SSE$ by degrees of freedom, $n-k$ , improvements in fit that result from increases in the number of variables are offset in part by a reduction in degrees of freedom. \n",
    "\n",
    "Finally, we calculate the covariance matrix, $(X'X)^{-1}$:\n",
    "\n",
    "$\\sigma^2 (X'X)^{-1}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9feab6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use results tab to retrieve our k and n variables for calculation\n",
    "# create estimator variance calculation\n",
    "\n",
    "n = results.nobs\n",
    "k = len(results.params)\n",
    "estimator_variance = SSE / (n - k)\n",
    "n, k, estimator_variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c6044f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# covariance matrix\n",
    "\n",
    "cov_matrix = results.cov_params()\n",
    "cov_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef19daf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "XtX = np.matmul(X.T,X)\n",
    "XtX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4acf70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "XtXInv = np.matrix(np.matmul(X.T, X)).getI()\n",
    "XtXInv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ca927f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate covariance matrix by hand (using matrices)\n",
    "# XtXInv = np.matrix(np.matmul(X.T, X)).getI()\n",
    "\n",
    "# multiply by estimator_variance\n",
    "ev_mul_XtXInv = estimator_variance * XtXInv\n",
    "\n",
    "# transform into pandas dataframe for easy visual \n",
    "pd.DataFrame(ev_mul_XtXInv, \n",
    "             columns = X.keys(), index = X.keys())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d36e7470",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we need to compare these to the other results\n",
    "\n",
    "results.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6667df34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show betas and compare to x_vars in covariance matrix\n",
    "\n",
    "# create our own regression output based on manual computation \n",
    "# (same as above pre-made process)\n",
    "\n",
    "parameters = {}\n",
    "\n",
    "#print(\"beta\", \"\\t\\t\\tSE\")\n",
    "for x_var in X.keys():\n",
    "    beta_x = results.params[x_var]\n",
    "    StdErrX = cov_matrix.loc[x_var][x_var]**.5\n",
    "#    print(beta_x, StdErrX, sep = \"\\t\")\n",
    "#    print(\"t:\", beta_x / StdErrX)\n",
    "    parameters[x_var] = {}\n",
    "    parameters[x_var][\"Beta\"] = beta_x\n",
    "    parameters[x_var][\"SE\"] = StdErrX\n",
    "    parameters[x_var][\"t-stats\"] = beta_x / StdErrX\n",
    "parameters = pd.DataFrame(parameters).T\n",
    "parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "759af0f1",
   "metadata": {},
   "source": [
    " # Calculate $R^2$\n",
    "\n",
    "The variance term will be used to help us calculate other values. First we estimate the square root of the mean squared error. Since the mean squared error is the variance of the estimator, this means we simply take the square root the variance term\n",
    "\n",
    "$rootMSE = \\sqrt{\\sigma^2}$\n",
    "\n",
    "The square-root of the MSE provides a more readily interpretable estimate of the estimator variance, showing the average distance of predicted values from actual values, corrected for the number of independent variables. \n",
    "\n",
    "We also estimate the R2 value. This value indicates the explanator power of the regression\n",
    "\n",
    "$R^2 = \\frac{SSR}{SST}$\n",
    "\n",
    "This compares the average squared distance between the predicted values and the average value against the average squared distance between observed values and average values. Ordinary least squares regression minimizes the squared distance between the predicted value and the average value. If values are perfectly predicted, then the SSR would equal the SST. Usually, the SSR is less than the SST. It will never be greater than the SST.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e4bc894",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate rsquared\n",
    "r2 = SSR / SST\n",
    "r2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cbbbff6",
   "metadata": {},
   "source": [
    "### Adjusted R-Squared\n",
    "Although the $R^2$ is a useful measure to understand the quality of the explanation provided by the selected exogenous variables. Recall that:\n",
    "\n",
    "$R^2 = \\frac{SSR}{SST}$\n",
    "\n",
    "\n",
    "Notice that as the degrees of freedom decrease, the numerator necessarily decreases as well. One should not depend solely on the adjusted $R^2$ to consider the strength of a regression's results, but it is often useful to help gauge whether or not a marginal addition of a variable improves explanatory power of a regression.\n",
    "\n",
    "${R^2}_{Adjusted} = 1 - \\frac{\\frac{SSE}{n - k}}{\\frac{SST}{n-1}}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004da76f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# as the number of explanitory variables increases, the adjusted r2 reduces in value\n",
    "\n",
    "r2_adjusted = 1 - (SSE / (n - k)) / (SST / (n - 1))\n",
    "r2_adjusted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe5379c",
   "metadata": {},
   "source": [
    "# Check the distribution of residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45041221",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams.update({\"font.size\":26})\n",
    "fig, ax = plt.subplots(figsize = (12,8))\n",
    "reg_data[[\"Residuals\"]].plot.hist(bins = 100, ax = ax)\n",
    "plt.xticks(rotation=90)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b443fbbc",
   "metadata": {},
   "source": [
    "### thinking through unit-root and Cointegration problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24493ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the real GDP per capita vs our economic freedom\n",
    "\n",
    "# difference graph showed below of five year differences\n",
    "\n",
    "# data bias present since recent data is more easily found,\n",
    "# old data appears more intermittently, so inherit bias is found here\n",
    "\n",
    "plot_df = data.loc[\"USA\"][x_vars + y_var]\n",
    "fig, ax = plt.subplots(figsize = (24,12))\n",
    "plot_df.diff(5).dropna().plot.line(ax = ax, secondary_y = y_var, legend = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "574403cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using log difference helps to push assumptions towards a normalized \n",
    "# distribution. Below it shows this distribution with few outliers\n",
    "\n",
    "np.log(data[y_var]).diff(5).plot.hist(bins = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c7983ba",
   "metadata": {},
   "source": [
    "### Warning: having more recent data biases estimates toward present inferences from present data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6fefc1d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Regressions with Logged Differences\n",
    "years_diff = 5\n",
    "reg_data = data\n",
    "# take the log of real gdp then group by difference\n",
    "reg_data[\"RGDP Per Capita\"] = np.log(data[\"RGDP Per Capita\"]).groupby(\n",
    "    \"ISO_Code_3\").diff(years_diff)\n",
    "\n",
    "# replace infinite values with null values since it will cause issues\n",
    "reg_data = reg_data.replace([np.inf, -np.inf], np.nan)\n",
    "reg_data.loc[\"USA\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "977426ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_df = reg_data.dropna(axis = 0, how = \"any\")\n",
    "y = r_df[y_var]\n",
    "X = r_df[x_vars]\n",
    "X[\"Constant\"] = 1\n",
    "results = sm.OLS(y, X).fit()\n",
    "r_df[\"Predictor\"] = results.predict()\n",
    "r_df[\"Residuals\"] = results.resid\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476c3029",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37bc898c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the residuals from the above. \n",
    "# This looks reasonable for a normal distribution\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (12,8))\n",
    "r_df[[\"Residuals\"]].plot.hist(bins = 100, ax = ax)\n",
    "\n",
    "# vertical line plot of mean of residuals\n",
    "ax.axvline(r_df[\"Residuals\"].mean(), ls = \"--\", linewidth = 5, color  = \"k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b90db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dictionary with results\n",
    "results_dict = {\"Beta\":results.params,\n",
    "               \"t-stats\": results.tvalues,\n",
    "               \"p-values\": results.pvalues,\n",
    "               \"SE\": results.bse}\n",
    "\n",
    "\n",
    "\n",
    "results_df = pd.DataFrame(results_dict).round(3)\n",
    "results_df.to_csv(\"y = RGPDPC, X = EFW, LogDiffResults\")\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e41b59ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# graph scatter of predictor and RGDP per capita (Predicted vs Observed)\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (20,12))\n",
    "r_df.plot.scatter(x = y_var[0],\n",
    "                 y = \"Predictor\",\n",
    "                 s = 50,\n",
    "                 alpha = .7,\n",
    "                 ax = ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e876362",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create residual plot functions below.\n",
    "\n",
    "\n",
    "def plot_residuals(df, y_var, x_vars):\n",
    "    fig, ax = plt.subplots(figsize = (14,10))\n",
    "    df.plot.scatter(x = y_var[0],y = \"Predictor\", s = 30, ax = ax)\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "    #cycle through all variables included in our variables\n",
    "    # use a for loop and graph through\n",
    "                   \n",
    "    for var in y_var + x_vars:\n",
    "        fig, ax = plt.subplots(figsize = (14,10))\n",
    "        df.plot.scatter(x = var,\n",
    "                     y = \"Residuals\", \n",
    "                      s = 30, ax = ax)\n",
    "        ax.axhline(0, ls = \"--\", color = \"k\")\n",
    "        plt.xticks(rotation=90)\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "plot_residuals(r_df, y_var, x_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087456a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add one to every value so our cumulative products don't result in 0\n",
    "cumulative_data = r_df[[y_var[0], \"Predictor\"]] + 1\n",
    "cumulative_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ef1c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create plots of RGDP per capita and predictor value\n",
    "\n",
    "for country in countries:\n",
    "    try:\n",
    "        plot_data = r_df.loc[country]\n",
    "        fig, ax = plt.subplots(figsize = (12,10))\n",
    "        plot_data[y_var + [\"Predictor\"]].add(1).cumprod().plot.line(ax = ax,\n",
    "                                                           legend = True)\n",
    "    except:\n",
    "        print(country + \"does not appear to be in index\")\n",
    "    ax.set_title(country)\n",
    "    plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93b1424",
   "metadata": {},
   "outputs": [],
   "source": [
    "# recreate our regression except using a new capita lag.\n",
    "\n",
    "r_df = reg_data.copy()\n",
    "r_df[\"RGDP Per Capita Lag\"] = reg_data[\n",
    "    \"RGDP Per Capita\"].groupby(\"ISO_Code_3\").shift(years_diff)\n",
    "r_df = r_df.dropna(axis = 0, how = \"any\")\n",
    "x_vars.append(\"RGDP Per Capita Lag\")\n",
    "y = r_df[y_var]\n",
    "X = r_df[x_vars]\n",
    "X[\"Constant\"] = 1\n",
    "results = sm.OLS(y, X).fit()\n",
    "r_df[\"Predictor\"] = results.predict()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc74881a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot residuals to see if assumptions met\n",
    "r_df[\"Residuals\"] = results.resid\n",
    "fig, ax = plt.subplots(figsize = (12,8))\n",
    "r_df[[\"Residuals\"]].plot.hist(bins = 100, ax = ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cbd57a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot residuals to see if there is a hidden bias\n",
    "plot_residuals(r_df, y_var, x_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b0dcad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean data from previous regression\n",
    "del r_df[\"Predictor\"]\n",
    "del r_df[\"Residuals\"]\n",
    "del r_df[\"RGDP Per Capita Lag\"]\n",
    "r_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da9aa769",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix x_vars and y_var to be indicative of new variable choices\n",
    "x_vars, y_var = list(r_df.keys()[2:7]), [r_df.keys()[7]]\n",
    "r_df[y_var + x_vars]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac20a8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# take the difference of the variables over time\n",
    "\n",
    "r_df = r_df[y_var + x_vars].groupby(\"ISO_Code_3\").diff(years_diff)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceeac32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropna\n",
    "r_df = r_df.dropna(axis = 0, how = \"any\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c792700",
   "metadata": {},
   "outputs": [],
   "source": [
    "# regression output using new vars and predictor\n",
    "y = r_df[y_var]\n",
    "X = r_df[x_vars]\n",
    "X[\"Constant\"] = 1\n",
    "results = sm.OLS(y, X).fit()\n",
    "r_df[\"Predictor\"] = results.predict()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cddd02ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "r_df[\"Residuals\"] = results.resid\n",
    "fig, ax = plt.subplots(figsize = (12,8))\n",
    "r_df[[\"Residuals\"]].plot.hist(bins = 100, ax = ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ff93d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_residuals(r_df, y_var, x_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e4556c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c9f934",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
